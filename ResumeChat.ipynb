{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RiOUkkK45ewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d3ae8e-c2c8-46fd-87a4-a210cfa6e5fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-3.15.5-py3-none-any.whl (272 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.6/272.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.15.5\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install chromadb\n",
        "# !pip install -Uq chromadb numpy datasets\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install pypdf\n",
        "!pip install python-dotenv\n",
        "!pip install tiktoken\n",
        "!pip install numpy==1.22\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KII1wK-x8BCB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "u3XmEvNO5vg_"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = [PyPDFLoader(\"resumenew.pdf\"),PyPDFLoader(\"shivam.pdf\")]\n",
        "docs = []\n",
        "for load in loader:\n",
        "  docs.extend(load.load())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "xzvTnIBMUS7W",
        "outputId": "6af53971-0268-4ac9-92f6-20ca1ef258a9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rohit Kumar \\nRanchi , Jharkhand  +91-9798494187 rohitcode005@gmail.com linkedin EDUCATION EXPERIENCE Sarala Birla University \\nB.Tech in Artificial Intelligence Data Engineer Intern Taiyo.ai March 2021-Present July 2023 Sep 2023 Dec 2022 Jun 2021 - Sep 2021 May 2021 - Present All India Samsung solve for tomorrow - Innovation Conduct web scraping to extract data from both the World Bank and IADB etc websites\\nestablishment of a robust data pipeline for seamless integration with Google Cloud.\\nEmploy Python scripting, emphasizing Object-Oriented Programming (OOP) principles\\nEffectively preprocess this data using Pandas and NumPy. Predict user emotions from audio input using a Flask website trained on 2,800 audio data samples across 7\\nemotions: happy, sad, surprise, fear, angry, disgust, and neutral. Flask web app that classify and Localize input image from CIFAR-10,specifically distingusing between\\neggplant and cucumber Functionality: A platform for HR to upload and manage hundreds of resumes simultaneously.\\nFiltering: HR can filter resumes based on project development needs or employee requirements using\\nqueries \\nResume Insights: Provides insights into resume data, aiding HR decision-making. \\nChat Feature: Users can engage in real-time chat with resume data. \\nTechnology Stack: Built using Langchain and fine-tuned with OpenAI and FAISS , Python , Streamlit  \\nTechnical: C, C++, Deep Learning, TensorFlow, LLM, Data Science (NumPy, pandas, Matplotlib), scikit- \\nlearn, Python, OOP, Langchain, OpenCV, Android App Development, Firebase, Git, Postman, Flask, React. \\nNon Technical : Teamwork , Leadership , Problem solving , Presentation skill , Event Planning SKILLS PROJECTS POSITION  AI ResumeRover Android App on Playstore Speech Emotion Recognition Samsung Solve For Tomorrow Image Localization and Classification Codeddit App : Community App for Programmers 8k+ downloads (Java & firebase) Machine Learning Lead - Google Developers Student Club (GDSC) Top 30 Kendriya vidyalaya \\nClass 12th 92.2% ACHIEVEMENTS Laper App Instant Programming support (Kotlin , firebase,nodejs,mongodb) Github Kaggle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rH_SdqF16RQd"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 300,\n",
        "    chunk_overlap = 50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Z3J1qCDN7YDs"
      },
      "outputs": [],
      "source": [
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ibzYEPnO7e0a"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "NRSaoXEu7gAN"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./docs/chroma  # remove old database files if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "AD1VX7b_Pwok"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'docs/chroma/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.faiss import FAISS\n",
        "\n",
        "vectordb = FAISS.from_documents(splits, embedding)"
      ],
      "metadata": {
        "id": "sg36obfC-6Z9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.vectorstores import Chroma\n",
        "# vectordb = Chroma.from_documents(\n",
        "#     documents=splits,\n",
        "#     embedding=embedding,\n",
        "#     persist_directory=persist_directory\n",
        "# )\n"
      ],
      "metadata": {
        "id": "AqtHP9DS-2Wb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "O9JVqNNGPyd1"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "llm_name = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name=llm_name, temperature=1)\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"who has done MTech\"})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "vkzkC6g9seGz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f283cc35-7c79-42a4-cad7-5f293accdc32"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Shivam Chhirolya has done MTech in Artificial Intelligence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lQO-PoSmsntE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}