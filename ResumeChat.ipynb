{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiOUkkK45ewo"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eAD6Jw5ORJT",
        "outputId": "939da35a-b2db-4dd4-9762-97f0defe9d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.15.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf\n",
        "# !pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46blmuHj98WX",
        "outputId": "3ebbfa10-f12c-4c4a-ac55-f887bcd01bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8nJC2bKdPd-",
        "outputId": "e1f91eec-7d52-4e2d-c877-d40c4abc05e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq chromadb numpy datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crZ0S64HdxgE"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "cebSXwe-d1u1",
        "outputId": "02d07d16-b571-4080-b37c-628a7b003e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.10.1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.2 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.22.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install numpy==1.22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KII1wK-x8BCB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvJRP2hQvByM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3XmEvNO5vg_"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = [PyPDFLoader(\"rohit.pdf\")]\n",
        "docs = []\n",
        "for load in loader:\n",
        "  docs.extend(load.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "0sYRzPL-6OjK",
        "outputId": "0060d958-37c0-4e8b-e65f-edcd48ff84a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Rohit KumarINTERNSHIP EXPERIENCE EDUCATIONSarala Birla University  Dec 2021 - May 2025 B.Tech in Artificial Intelligence Senior Secondary Education XII : 92.2% SKILLS Technical Skills: +91-9798494187 rohitcode005@gmail.com Ranchi , Jharkhand Data Science: Pandas, NumPy, Scikit-learn\\nDeep Learning: TensorFlow, OpenCV, LLM,\\nCNN, RNN , Langchain\\nDevelopment: Android, React, Flask\\nAdditional: Deployment, MySQL, Postman,\\nBeautiful Soup, PowerBI, Firebase, Git &\\nGitHubProgramming Language: Python , C, C++ , Java , oops , Javascript ,\\nHTMLData Engineer Taiy≈ç.AI, Modern Intelligence for Global Infrastructure Jun 2021 -  Sep 2021 Perform web scraping of data from the World Bank and IADB websites,\\ncreate a data pipeline to upload it to Google Cloud, and write Python\\nscripts using Object-Oriented Programming (OOP) principles for data\\npreprocessing with Pandas and NumPy.Data AnnotatorMarch 2023 - Jun 2023 KoiReader PROJECTS Speech Emotion Recognition Predict user emotions from audio input using a Flask website trained on\\n2,800 audio data samples across 7 emotions: happy, sad, surprise, fear,\\nangry, disgust, and neutral.\\nhttps://github.com/Rohitw3code/speech-emotion-recognitionMovie Recommendation Text Sentimental Analysis NLP Scrape data from the Black Coffee website, apply text analysis using\\nNLP, and generate sentiment scores.\\nhttps://github.com/Rohitw3code/Text-AnalysisImage Localization and Classification Flask web app that classifies and localizes input images from the CIFAR-10\\ndataset, specifically distinguishing between eggplant and cucumber.\\nhttps://github.com/Rohitw3code/Image--classification-and-Localization-\\nCIFAR10Face2Emoji GestureSPS HACKATHON RAJASTHAN  \\n03/2023SafeRoute: Enhancing rider safety through\\nreal-time accident risk detection and\\nemergency supportCodeddit : Codeddit is a collaborative\\ncoding platform that enables developers to\\nshare, discuss, and work on code together in\\nreal-time. 5k+ downloadLaper App: Instant expert assistance for\\nsolving programming problems in real-time.Detecting and Displaying Corresponding Emojis\\nhttps://github.com/Rohitw3code/Computer-vision-Emojis-DetectorMY APPS AVILABLE ON PLAY STORE https://github.com/Rohitw3code Selected in all india TOP 30 \\nSolve for Tomorrow by samsungDesigned a proficient movie recommendation system utilizing the TMDB\\ndataset.\\nDeveloped a user-friendly web application for easy deployment and user\\ninteraction.Introducing a novel app, inspired by the classic game of tic-tac-toe. It\\noffers a multiplayer, real-time online gaming experience and is now\\navailable on the Play Store./rohit-kumar-66522518a/ Computer Vision Hand Gesture Game-Play Stone-Paper-Scissors LLM - Fine tuning Pretrained model : distilbert-base-uncased and squad_v2\\nfine tuning on question answering   July 2023 Aug 2023 May 2023 Nov 2022 Dec 2022 Dec 2022 Dec 2022 Tic Tac Toggle App March 2022 Machine Learning Lead - \\nGoogle Developers Student Club (GDSC)I have experience in data annotation tools, specifically LabelMe and\\nmakesense.ai. I've successfully completed 10,000 image\\nannotations, consistently delivering high-quality work.Award https://www.kaggle.com/rohitcode123\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH_SdqF16RQd"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 300,\n",
        "    chunk_overlap = 50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3J1qCDN7YDs"
      },
      "outputs": [],
      "source": [
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibzYEPnO7e0a"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NRSaoXEu7gAN"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./docs/chroma  # remove old database files if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0QnZxhhZQcbb"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb\n",
        "!pip install pydantic-settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBV3LlJMReb9",
        "outputId": "118a9b25-1aa1-43c2-9ecd-20795e9baefb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RyNDe-EfUc6"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AD1VX7b_Pwok"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "persist_directory = 'docs/chroma/'\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9JVqNNGPyd1"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "llm_name = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"what is the collage of rohit\"})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "vkzkC6g9seGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lQO-PoSmsntE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}